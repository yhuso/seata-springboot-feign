server.port = 10000

spring.application.name = seata-order
server.tomcat.uri-encoding=UTF-8
server.servlet.context-path = /

logging.level.root = info
#logging.level.com.aha.tech.model.mapper=debug

swagger.enable = off

# mysql readwrite数据源
readwritedb.enable = on

jdbc.readwrite.driverClassName = com.mysql.jdbc.Driver
jdbc.readwrite.jdbcUrl = jdbc:mysql://test-basics:3306/seata_order?useUnicode=true&characterEncoding=utf8
jdbc.readwrite.username = hjm_dev
jdbc.readwrite.password = hjm_dev
jdbc.readwrite.connectionTimeout = 5000
jdbc.readwrite.idleTimeout = 1000
jdbc.readwrite.maximumPoolSize = 50
jdbc.readwrite.minimumIdle = 5

##redis
spring.redis.host = test-basics
spring.redis.port = 6379
spring.redis.password =
# 连接超时时间（毫秒）
spring.redis.timeout = 10000ms
# dev环境用的是2 真是吊的不行,共享内存还要分,namespace都没.吐槽下
spring.redis.database = 8
# 连接池最大连接数（使用负值表示没有限制） 默认 8
spring.redis.lettuce.pool.max-active = 10
# 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1
spring.redis.lettuce.pool.max-wait = -1ms
# 连接池中的最大空闲连接 默认 8
spring.redis.lettuce.pool.max-idle = 5
# 连接池中的最小空闲连接 默认 0
spring.redis.lettuce.pool.min-idle = 0
request_max_payload = 500


# kafka
kafka.enable = off
kafka.producer.bootstrap-servers = test-basics:9092
kafka.producer.retries = 3
kafka.producer.batch-size = 8096
kafka.producer.linger-ms = 5
kafka.producer.buffer-memory = 33554432
kafka.poll.timeout = 2000

kafka.consumer.bootstrap-servers = test-basics:9092
kafka.consumer.group-id = ${spring.application.name}
kafka.consumer.enable-auto-commit = false
kafka.consumer.auto-commit-interval-ms = 1000
kafka.consumer.session-timeout-ms = 30000
kafka.consumer.max-poll-records = 500
kafka.consumer.max.poll.interval.ms = 15000
#earliest,latest
kafka.consumer.auto-offset-reset = latest

# kafka topics
kafka.topic.contract.consumer = order_member_contract_created
kafka.topic.removecontract.consumer = pay_subscribe_insert
kafka.topic.order.consumer = order_member_order_add
kafka.topic.withhold.consumer = pay_withhold_insert

kafka.topic.cannotAddMemberPrivilege.producer = member_order_privilege_updated
kafka.topic.memberPrivilegeCreateOrUpdate.producer = member_privilege_created_or_updated
kafka.topic.hongdao.subscribe.consumer = rule_hongdao_subscribed
kafka.topic.ios.receipt.consumer = order_contract_ios_receipt_upload




#初始化启动方法开启
WithholdTask.cron = 0 */1 * * * ?

# messagepush 任务
MemberNoticeStrategyTask.cron = 0/10 * * * * ?

MemberStatusTask.cron = 0 */1 * * * ?

# 消息重试
MessageCompensationTask.cron = 0 */5 * * * ?

# 推送消息
MsgPreSendTask.cron = 0 */3 * * * ?
# 弘道会员检查
MemberHongDaoTask.cron = 0 5 0 * * ?
# 系统解约任务
systemRemoveContract.cron = 0 0 1 * * ?



## nacos cluster 地址 集群环境用逗号分隔
spring.cloud.nacos.discovery.server-addr = 10.10.68.199:8848,10.10.178.170:8848,10.10.26.255:8848
## namespaceId 环境id
##test1
spring.cloud.nacos.discovery.namespace = e9c392fa-69a7-4272-b20b-123c19df1ed8
##test2
##spring.cloud.nacos.discovery.namespace = e96b0c34-53ce-4d4e-bb2c-2b59776a4204
##test4
##spring.cloud.nacos.discovery.namespace = d385b1ac-646d-4559-906c-6014c2caf6fe
##test5
##spring.cloud.nacos.discovery.namespace = fb01c7f7-48ec-4bd1-a8ef-9723828411f4
##test6
##spring.cloud.nacos.discovery.namespace = e3fc243d-317b-49a9-8c68-a09cae5d75a0
#
# 注册上去的服务名 大小写敏感 全小写
spring.cloud.nacos.discovery.service = ${spring.application.name}
spring.cloud.nacos.discovery.namingLoadCacheAtStart = true
# 忽略的网卡 需要忽略docker*,lo*,vip*等
spring.cloud.inetutils.ignored-interfaces[0] = lo*
spring.cloud.inetutils.ignored-interfaces[1] = docker*
spring.cloud.nacos.discovery.register-enabled=true

#弘道合作会员的等级id
hongdao.member.level.id = 7

current_env = test
today = 2019-09-17


# Seata 应用名称，默认使用 ${spring.application.name}
seata.application-id = ${spring.application.name}
# Seata 事务组, 高版本没找到相关配置, 是否可配置未知 选用默认default
seata.tx-service-group = default
# 服务配置项
# 虚拟组和分组的映射 1.0.0以上好像将vgroup-mapping 改为 vgroupMapping, 此处是否影响未测试
# 此处Key对应 tx-service-group 的 Value, 此处 value 默认 default
seata.service.vgroupMapping.default = default

# 分组和 Seata 服务的映射 默认端口8091
seata.service.grouplist.default=127.0.0.1:8091
